{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0513c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/10], Loss: 1311.7113, Accuracy: 47.26%\n",
      "Epoch [2/10], Loss: 1079.2195, Accuracy: 53.05%\n",
      "Epoch [3/10], Loss: 994.9199, Accuracy: 54.40%\n",
      "Epoch [4/10], Loss: 940.4686, Accuracy: 56.50%\n",
      "Epoch [5/10], Loss: 894.0639, Accuracy: 57.98%\n",
      "Epoch [6/10], Loss: 860.0616, Accuracy: 59.23%\n",
      "Epoch [7/10], Loss: 825.8300, Accuracy: 59.22%\n",
      "Epoch [8/10], Loss: 793.0323, Accuracy: 59.55%\n",
      "Epoch [9/10], Loss: 766.4474, Accuracy: 59.56%\n",
      "Epoch [10/10], Loss: 741.7228, Accuracy: 60.07%\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# FORCE GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not available. Please enable CUDA.\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transform (normalize CIFAR)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "# LeNet Model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)   # changed input channel to 3\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))   # 32->28->14\n",
    "        x = self.pool(torch.relu(self.conv2(x)))   # 14->10->5\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop (10 epochs)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c1b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# FORCE GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not available. Please enable CUDA.\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transform (normalize CIFAR)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, epochs=10, lr=0.001):\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    total_batches = len(trainloader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f\"\\nðŸš€ Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # âœ… UNIVERSAL INCEPTION HANDLER\n",
    "            if hasattr(outputs, \"logits\"):  # New PyTorch Inception\n",
    "                main_output = outputs.logits\n",
    "                aux_output = outputs.aux_logits\n",
    "                loss = criterion(main_output, labels)\n",
    "\n",
    "                if aux_output is not None:\n",
    "                    loss += 0.4 * criterion(aux_output, labels)\n",
    "\n",
    "                final_output = main_output\n",
    "\n",
    "            elif isinstance(outputs, tuple):  # Older versions\n",
    "                main_output, aux_output = outputs\n",
    "                loss = criterion(main_output, labels) + \\\n",
    "                       0.4 * criterion(aux_output, labels)\n",
    "                final_output = main_output\n",
    "\n",
    "            else:  # Normal models\n",
    "                loss = criterion(outputs, labels)\n",
    "                final_output = outputs\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(final_output, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            running_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "            sys.stdout.write(\n",
    "                f\"\\rBatch [{batch_idx+1}/{total_batches}] \"\n",
    "                f\"Running Train Acc: {running_accuracy:.2f}%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # ðŸ”Ž Evaluation\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Handle Inception outputs\n",
    "                if hasattr(outputs, \"logits\"):\n",
    "                    outputs = outputs.logits\n",
    "                elif isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "        print(f\"\\nâœ… Epoch {epoch+1} Complete | \"\n",
    "              f\"Train Acc: {train_accuracy:.2f}% | \"\n",
    "              f\"Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"\\nTraining Finished ðŸš€\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU cache cleared âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c018e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1253.8102, Accuracy: 55.36%\n",
      "Epoch [2/10], Loss: 938.0080, Accuracy: 62.43%\n",
      "Epoch [3/10], Loss: 800.3549, Accuracy: 68.11%\n",
      "Epoch [4/10], Loss: 717.8503, Accuracy: 69.62%\n",
      "Epoch [5/10], Loss: 647.4908, Accuracy: 70.87%\n",
      "Epoch [6/10], Loss: 596.8149, Accuracy: 71.46%\n",
      "Epoch [7/10], Loss: 555.8709, Accuracy: 73.69%\n",
      "Epoch [8/10], Loss: 513.0678, Accuracy: 74.27%\n",
      "Epoch [9/10], Loss: 484.2147, Accuracy: 74.74%\n",
      "Epoch [10/10], Loss: 452.7208, Accuracy: 76.40%\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "class AlexNet_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet_CIFAR, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # 32 -> 16\n",
    "\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # 16 -> 8\n",
    "\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)   # 8 -> 4\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 4 * 4, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(4096, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = AlexNet_CIFAR().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19c12c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch [0/782] Loss: 2.5525\n",
      "Epoch [1/5] Batch [100/782] Loss: 1.5754\n",
      "Epoch [1/5] Batch [200/782] Loss: 1.5595\n",
      "Epoch [1/5] Batch [300/782] Loss: 1.2969\n",
      "Epoch [1/5] Batch [400/782] Loss: 1.8074\n",
      "Epoch [1/5] Batch [500/782] Loss: 1.6756\n",
      "Epoch [1/5] Batch [600/782] Loss: 1.3521\n",
      "Epoch [1/5] Batch [700/782] Loss: 1.3890\n",
      "âœ… Epoch [1/5] Final Loss: 1204.5644 Test Accuracy: 59.73%\n",
      "\n",
      "Epoch [2/5] Batch [0/782] Loss: 1.6999\n",
      "Epoch [2/5] Batch [100/782] Loss: 1.4707\n",
      "Epoch [2/5] Batch [200/782] Loss: 1.5450\n",
      "Epoch [2/5] Batch [300/782] Loss: 1.5055\n",
      "Epoch [2/5] Batch [400/782] Loss: 1.7289\n",
      "Epoch [2/5] Batch [500/782] Loss: 1.1932\n",
      "Epoch [2/5] Batch [600/782] Loss: 1.1339\n",
      "Epoch [2/5] Batch [700/782] Loss: 1.6635\n",
      "âœ… Epoch [2/5] Final Loss: 1116.9807 Test Accuracy: 60.96%\n",
      "\n",
      "Epoch [3/5] Batch [0/782] Loss: 1.4482\n",
      "Epoch [3/5] Batch [100/782] Loss: 1.1631\n",
      "Epoch [3/5] Batch [200/782] Loss: 1.2441\n",
      "Epoch [3/5] Batch [300/782] Loss: 1.5925\n",
      "Epoch [3/5] Batch [400/782] Loss: 1.1870\n",
      "Epoch [3/5] Batch [500/782] Loss: 1.4953\n",
      "Epoch [3/5] Batch [600/782] Loss: 1.5203\n",
      "Epoch [3/5] Batch [700/782] Loss: 1.4185\n",
      "âœ… Epoch [3/5] Final Loss: 1087.8792 Test Accuracy: 61.55%\n",
      "\n",
      "Epoch [4/5] Batch [0/782] Loss: 1.4965\n",
      "Epoch [4/5] Batch [100/782] Loss: 1.3235\n",
      "Epoch [4/5] Batch [200/782] Loss: 1.5287\n",
      "Epoch [4/5] Batch [300/782] Loss: 1.4564\n",
      "Epoch [4/5] Batch [400/782] Loss: 1.0941\n",
      "Epoch [4/5] Batch [500/782] Loss: 1.4312\n",
      "Epoch [4/5] Batch [600/782] Loss: 1.3820\n",
      "Epoch [4/5] Batch [700/782] Loss: 1.2540\n",
      "âœ… Epoch [4/5] Final Loss: 1055.4050 Test Accuracy: 60.77%\n",
      "\n",
      "Epoch [5/5] Batch [0/782] Loss: 1.2688\n",
      "Epoch [5/5] Batch [100/782] Loss: 1.2914\n",
      "Epoch [5/5] Batch [200/782] Loss: 1.3092\n",
      "Epoch [5/5] Batch [300/782] Loss: 1.3959\n",
      "Epoch [5/5] Batch [400/782] Loss: 1.5158\n",
      "Epoch [5/5] Batch [500/782] Loss: 1.1311\n",
      "Epoch [5/5] Batch [600/782] Loss: 1.3165\n",
      "Epoch [5/5] Batch [700/782] Loss: 1.3057\n",
      "âœ… Epoch [5/5] Final Loss: 1029.0813 Test Accuracy: 61.09%\n",
      "\n",
      "Training Finished ðŸš€\n"
     ]
    }
   ],
   "source": [
    "class VGG16_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_CIFAR, self).__init__()\n",
    "        \n",
    "        # Load pretrained VGG16\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # ðŸ”¥ Freeze convolution layers (SPEED BOOST)\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer for 10 classes\n",
    "        self.vgg.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "vgg_model = VGG16_CIFAR()\n",
    "\n",
    "# Train (uses your existing train_model function + loaders)\n",
    "vgg_acc = train_model(vgg_model, trainloader, testloader, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe93eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57a32313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Train Loss: 774.2333 Train Acc: 66.62% Test Acc: 73.20%\n",
      "Epoch [2/5] Train Loss: 512.7203 Train Acc: 77.63% Test Acc: 73.92%\n",
      "Epoch [3/5] Train Loss: 384.1874 Train Acc: 83.05% Test Acc: 74.38%\n",
      "Epoch [4/5] Train Loss: 301.9743 Train Acc: 86.88% Test Acc: 74.25%\n",
      "Epoch [5/5] Train Loss: 246.1540 Train Acc: 89.86% Test Acc: 73.42%\n",
      "Training Finished ðŸš€\n"
     ]
    }
   ],
   "source": [
    "class ResNet50_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_CIFAR, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet = models.resnet50(\n",
    "            weights=models.ResNet50_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        \n",
    "        # ðŸ”¥ Freeze ALL layers first\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # âœ… Unfreeze last residual block (layer4)\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Replace final fully connected layer\n",
    "        self.resnet.fc = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "resnet_model = ResNet50_CIFAR()\n",
    "resnet_acc = train_model(resnet_model, trainloader, testloader, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fb57cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8] Train Loss: 769.2146 Train Acc: 65.65% Test Acc: 75.71%\n",
      "Epoch [2/8] Train Loss: 446.9526 Train Acc: 80.25% Test Acc: 78.38%\n",
      "Epoch [3/8] Train Loss: 304.4408 Train Acc: 86.56% Test Acc: 79.25%\n",
      "Epoch [4/8] Train Loss: 207.5968 Train Acc: 90.92% Test Acc: 78.70%\n",
      "Epoch [5/8] Train Loss: 147.8374 Train Acc: 93.42% Test Acc: 78.50%\n",
      "Epoch [6/8] Train Loss: 116.6685 Train Acc: 94.80% Test Acc: 79.34%\n",
      "Epoch [7/8] Train Loss: 95.5177 Train Acc: 95.88% Test Acc: 79.94%\n",
      "Epoch [8/8] Train Loss: 78.0274 Train Acc: 96.66% Test Acc: 79.39%\n",
      "Training Finished ðŸš€\n"
     ]
    }
   ],
   "source": [
    "class ResNet101_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet = models.resnet101(\n",
    "            weights=models.ResNet101_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "\n",
    "        # Freeze everything\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze layer4\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Unfreeze BatchNorm layers (important!)\n",
    "        for m in self.resnet.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        self.resnet.fc = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "resnet101_model = ResNet101_CIFAR()\n",
    "\n",
    "resnet101_acc = train_model(\n",
    "    resnet101_model,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    epochs=8,\n",
    "    lr=0.0003\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97ee1713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Epoch 1/7\n",
      "Batch [782/782] Running Train Acc: 71.79%\n",
      "âœ… Epoch 1 Complete | Train Acc: 71.79% | Test Acc: 78.83%\n",
      "\n",
      "ðŸš€ Epoch 2/7\n",
      "Batch [782/782] Running Train Acc: 76.52%\n",
      "âœ… Epoch 2 Complete | Train Acc: 76.52% | Test Acc: 79.91%\n",
      "\n",
      "ðŸš€ Epoch 3/7\n",
      "Batch [782/782] Running Train Acc: 77.14%\n",
      "âœ… Epoch 3 Complete | Train Acc: 77.14% | Test Acc: 80.91%\n",
      "\n",
      "ðŸš€ Epoch 4/7\n",
      "Batch [782/782] Running Train Acc: 77.48%\n",
      "âœ… Epoch 4 Complete | Train Acc: 77.48% | Test Acc: 81.03%\n",
      "\n",
      "ðŸš€ Epoch 5/7\n",
      "Batch [782/782] Running Train Acc: 77.86%\n",
      "âœ… Epoch 5 Complete | Train Acc: 77.86% | Test Acc: 81.12%\n",
      "\n",
      "ðŸš€ Epoch 6/7\n",
      "Batch [782/782] Running Train Acc: 77.93%\n",
      "âœ… Epoch 6 Complete | Train Acc: 77.93% | Test Acc: 81.25%\n",
      "\n",
      "ðŸš€ Epoch 7/7\n",
      "Batch [782/782] Running Train Acc: 77.90%\n",
      "âœ… Epoch 7 Complete | Train Acc: 77.90% | Test Acc: 81.20%\n",
      "\n",
      "Training Finished ðŸš€\n",
      "GPU cache cleared âœ…\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "class EfficientNet_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = models.efficientnet_b0(\n",
    "            weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "\n",
    "        # Freeze feature extractor\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "efficient_model = EfficientNet_CIFAR()\n",
    "\n",
    "# Train using your existing function\n",
    "efficient_acc = train_model(efficient_model, trainloader, testloader, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc2d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class InceptionV3_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load pretrained Inception v3\n",
    "        self.model = models.inception_v3(\n",
    "            weights=models.Inception_V3_Weights.IMAGENET1K_V1,\n",
    "            aux_logits=True   # IMPORTANT\n",
    "        )\n",
    "\n",
    "        # Freeze feature extractor\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace final FC layer\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, 10)\n",
    "\n",
    "        # Replace auxiliary classifier\n",
    "        if self.model.aux_logits:\n",
    "            aux_in = self.model.AuxLogits.fc.in_features\n",
    "            self.model.AuxLogits.fc = nn.Linear(aux_in, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Resize CIFAR (32x32) â†’ 299x299\n",
    "        x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "\n",
    "        if self.training:\n",
    "            outputs, aux_outputs = self.model(x)\n",
    "            return outputs, aux_outputs\n",
    "        else:\n",
    "            return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510011da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Epoch 1/7\n",
      "Batch [782/782] Running Train Acc: 66.00%\n",
      "âœ… Epoch 1 Complete | Train Acc: 66.00% | Test Acc: 75.49%\n",
      "\n",
      "ðŸš€ Epoch 2/7\n",
      "Batch [782/782] Running Train Acc: 70.72%\n",
      "âœ… Epoch 2 Complete | Train Acc: 70.72% | Test Acc: 75.59%\n",
      "\n",
      "ðŸš€ Epoch 3/7\n",
      "Batch [782/782] Running Train Acc: 71.11%\n",
      "âœ… Epoch 3 Complete | Train Acc: 71.11% | Test Acc: 75.94%\n",
      "\n",
      "ðŸš€ Epoch 4/7\n",
      "Batch [782/782] Running Train Acc: 71.22%\n",
      "âœ… Epoch 4 Complete | Train Acc: 71.22% | Test Acc: 76.62%\n",
      "\n",
      "ðŸš€ Epoch 5/7\n",
      "Batch [782/782] Running Train Acc: 71.48%\n",
      "âœ… Epoch 5 Complete | Train Acc: 71.48% | Test Acc: 76.58%\n",
      "\n",
      "ðŸš€ Epoch 6/7\n",
      "Batch [782/782] Running Train Acc: 71.46%\n",
      "âœ… Epoch 6 Complete | Train Acc: 71.46% | Test Acc: 77.32%\n",
      "\n",
      "ðŸš€ Epoch 7/7\n",
      "Batch [782/782] Running Train Acc: 71.26%\n",
      "âœ… Epoch 7 Complete | Train Acc: 71.26% | Test Acc: 76.28%\n",
      "\n",
      "Training Finished ðŸš€\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inception_model = InceptionV3_CIFAR()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m inception_acc = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minception_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining Finished ðŸš€\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mgc\u001b[49m.collect()\n\u001b[32m     99\u001b[39m torch.cuda.empty_cache()\n\u001b[32m    100\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGPU cache cleared âœ…\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3_CIFAR()\n",
    "inception_acc = train_model(inception_model, trainloader, testloader, epochs=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778639dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a9ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10] Loss: 0.2570 Train Accuracy: 33.65%\n",
      "Epoch [2/10] Loss: 0.0153 Train Accuracy: 97.69%\n",
      "Epoch [3/10] Loss: 0.0091 Train Accuracy: 98.70%\n",
      "Epoch [4/10] Loss: 0.0064 Train Accuracy: 99.07%\n",
      "Epoch [5/10] Loss: 0.0053 Train Accuracy: 99.24%\n",
      "Epoch [6/10] Loss: 0.0046 Train Accuracy: 99.38%\n",
      "Epoch [7/10] Loss: 0.0042 Train Accuracy: 99.41%\n",
      "Epoch [8/10] Loss: 0.0032 Train Accuracy: 99.59%\n",
      "Epoch [9/10] Loss: 0.0030 Train Accuracy: 99.61%\n",
      "Epoch [10/10] Loss: 0.0028 Train Accuracy: 99.65%\n",
      "\n",
      "Test Accuracy: 99.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# Data Loading\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# VGG-like Model for MNIST\n",
    "# ----------------------------\n",
    "class VGG_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_MNIST, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 3 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)  # 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG_MNIST().to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Loss + Optimizer\n",
    "# ----------------------------\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Convert labels to one-hot for BCE\n",
    "        labels_onehot = torch.zeros(labels.size(0), 10).to(device)\n",
    "        labels_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Accuracy: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nTest Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d052ed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_11892\\2083540561.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_11892\\2083540561.py:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Loss: 1.1988 Train Acc: 43.37%\n",
      "Epoch [2/20] Loss: 0.0799 Train Acc: 94.91%\n",
      "Epoch [3/20] Loss: 0.0446 Train Acc: 96.97%\n",
      "Epoch [4/20] Loss: 0.0323 Train Acc: 97.76%\n",
      "Epoch [5/20] Loss: 0.0258 Train Acc: 98.21%\n",
      "Epoch [6/20] Loss: 0.0211 Train Acc: 98.50%\n",
      "Epoch [7/20] Loss: 0.0175 Train Acc: 98.72%\n",
      "Epoch [8/20] Loss: 0.0151 Train Acc: 98.83%\n",
      "Epoch [9/20] Loss: 0.0138 Train Acc: 98.93%\n",
      "Epoch [10/20] Loss: 0.0115 Train Acc: 99.11%\n",
      "Epoch [11/20] Loss: 0.0099 Train Acc: 99.22%\n",
      "Epoch [12/20] Loss: 0.0088 Train Acc: 99.28%\n",
      "Epoch [13/20] Loss: 0.0083 Train Acc: 99.30%\n",
      "Epoch [14/20] Loss: 0.0076 Train Acc: 99.38%\n",
      "Epoch [15/20] Loss: 0.0067 Train Acc: 99.41%\n",
      "Epoch [16/20] Loss: 0.0057 Train Acc: 99.49%\n",
      "Epoch [17/20] Loss: 0.0048 Train Acc: 99.57%\n",
      "Epoch [18/20] Loss: 0.0045 Train Acc: 99.60%\n",
      "Epoch [19/20] Loss: 0.0042 Train Acc: 99.64%\n",
      "Epoch [20/20] Loss: 0.0039 Train Acc: 99.62%\n",
      "\n",
      "Final Test Accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# Device Setup\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ----------------------------\n",
    "# Data\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128,\n",
    "                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128,\n",
    "                         shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ----------------------------\n",
    "# AlexNet (Modified for MNIST)\n",
    "# ----------------------------\n",
    "class AlexNet_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet_MNIST, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Focal Loss (Multi-class)\n",
    "# ----------------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "model = AlexNet_MNIST().to(device)\n",
    "\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecefb5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_11892\\1521359946.py:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_11892\\1521359946.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 1.2583 Train Acc: 91.88%\n",
      "Epoch [2/15] Loss: 0.4571 Train Acc: 96.88%\n",
      "Epoch [3/15] Loss: 0.2982 Train Acc: 97.74%\n",
      "Epoch [4/15] Loss: 0.2340 Train Acc: 98.14%\n",
      "Epoch [5/15] Loss: 0.2380 Train Acc: 98.13%\n",
      "Epoch [6/15] Loss: 0.2601 Train Acc: 97.87%\n",
      "Epoch [7/15] Loss: 0.2617 Train Acc: 97.92%\n",
      "Epoch [8/15] Loss: 0.2584 Train Acc: 97.87%\n",
      "Epoch [9/15] Loss: 0.2549 Train Acc: 97.95%\n",
      "Epoch [10/15] Loss: 0.2553 Train Acc: 97.92%\n",
      "Epoch [11/15] Loss: 0.2554 Train Acc: 97.81%\n",
      "Epoch [12/15] Loss: 0.2524 Train Acc: 97.79%\n",
      "Epoch [13/15] Loss: 0.2615 Train Acc: 97.75%\n",
      "Epoch [14/15] Loss: 0.2557 Train Acc: 97.77%\n",
      "Epoch [15/15] Loss: 0.2565 Train Acc: 97.76%\n",
      "\n",
      "Final Test Accuracy: 97.66%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# ----------------------------\n",
    "# Device Setup\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ----------------------------\n",
    "# Data\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),  # ResNet prefers larger input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128,\n",
    "                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128,\n",
    "                         shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ----------------------------\n",
    "# ResNet Backbone (Modified)\n",
    "# ----------------------------\n",
    "class ResNet_MNIST(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(weights=None)\n",
    "\n",
    "        # Modify first conv layer for 1-channel\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features,\n",
    "                                     embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# ArcFace Layer\n",
    "# ----------------------------\n",
    "class ArcFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input),\n",
    "                          F.normalize(self.weight))\n",
    "        theta = torch.acos(torch.clamp(cosine, -1+1e-7, 1-1e-7))\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1,1), 1.0)\n",
    "\n",
    "        output = (one_hot * target_logits) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model + ArcFace Head\n",
    "# ----------------------------\n",
    "embedding_dim = 128\n",
    "num_classes = 10\n",
    "\n",
    "backbone = ResNet_MNIST(embedding_dim).to(device)\n",
    "arcface = ArcFace(embedding_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(backbone.parameters()) +\n",
    "                       list(arcface.parameters()), lr=0.001)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    backbone.train()\n",
    "    arcface.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            features = backbone(images)\n",
    "            outputs = arcface(features, labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "backbone.eval()\n",
    "arcface.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        features = backbone(images)\n",
    "        outputs = arcface(features, labels)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff0842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\2700741752.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\2700741752.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 0.3021 Train Acc: 22.54%\n",
      "Epoch [2/10] Loss: 0.2064 Train Acc: 52.42%\n",
      "Epoch [3/10] Loss: 0.1605 Train Acc: 65.30%\n",
      "Epoch [4/10] Loss: 0.1301 Train Acc: 72.71%\n",
      "Epoch [5/10] Loss: 0.1091 Train Acc: 77.81%\n",
      "Epoch [6/10] Loss: 0.0923 Train Acc: 81.58%\n",
      "Epoch [7/10] Loss: 0.0780 Train Acc: 84.71%\n",
      "Epoch [8/10] Loss: 0.0655 Train Acc: 87.44%\n",
      "Epoch [9/10] Loss: 0.0552 Train Acc: 89.43%\n",
      "Epoch [10/10] Loss: 0.0449 Train Acc: 91.68%\n",
      "\n",
      "Final Test Accuracy: 81.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Device Setup\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ----------------------------\n",
    "# Data (CIFAR-10)\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# VGG-like Model for CIFAR-10\n",
    "# ----------------------------\n",
    "class VGG_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_CIFAR10, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),  # changed to 3 channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),  # changed size (32→16→8→4)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG_CIFAR10().to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Loss + Optimizer\n",
    "# ----------------------------\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        # One-hot encoding for BCE\n",
    "        labels_onehot = torch.zeros(labels.size(0), 10, device=device)\n",
    "        labels_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels_onehot)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4477842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\3439532211.py:127: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\3439532211.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Loss: 1.7854 Train Acc: 15.09%\n",
      "Epoch [2/20] Loss: 1.2298 Train Acc: 33.60%\n",
      "Epoch [3/20] Loss: 0.9987 Train Acc: 42.77%\n",
      "Epoch [4/20] Loss: 0.8481 Train Acc: 49.85%\n",
      "Epoch [5/20] Loss: 0.7546 Train Acc: 54.31%\n",
      "Epoch [6/20] Loss: 0.6550 Train Acc: 59.36%\n",
      "Epoch [7/20] Loss: 0.5890 Train Acc: 62.90%\n",
      "Epoch [8/20] Loss: 0.5270 Train Acc: 66.31%\n",
      "Epoch [9/20] Loss: 0.4766 Train Acc: 69.37%\n",
      "Epoch [10/20] Loss: 0.4358 Train Acc: 71.52%\n",
      "Epoch [11/20] Loss: 0.3906 Train Acc: 74.10%\n",
      "Epoch [12/20] Loss: 0.3551 Train Acc: 75.88%\n",
      "Epoch [13/20] Loss: 0.3271 Train Acc: 77.58%\n",
      "Epoch [14/20] Loss: 0.2970 Train Acc: 78.93%\n",
      "Epoch [15/20] Loss: 0.2696 Train Acc: 80.34%\n",
      "Epoch [16/20] Loss: 0.2472 Train Acc: 81.76%\n",
      "Epoch [17/20] Loss: 0.2248 Train Acc: 82.99%\n",
      "Epoch [18/20] Loss: 0.1973 Train Acc: 84.60%\n",
      "Epoch [19/20] Loss: 0.1784 Train Acc: 85.64%\n",
      "Epoch [20/20] Loss: 0.1606 Train Acc: 86.59%\n",
      "\n",
      "Final Test Accuracy: 78.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# Device Setup\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ----------------------------\n",
    "# Data (CIFAR-10)\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# AlexNet for CIFAR-10\n",
    "# ----------------------------\n",
    "class AlexNet_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet_CIFAR10, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Focal Loss (Multi-class)\n",
    "# ----------------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "model = AlexNet_CIFAR10().to(device)\n",
    "\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=0.01,\n",
    "                      momentum=0.9,\n",
    "                      weight_decay=5e-4)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfb3c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\3999970323.py:127: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Krishna Mehra\\AppData\\Local\\Temp\\ipykernel_17076\\3999970323.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 7.6165 Train Acc: 30.30%\n",
      "Epoch [2/15] Loss: nan Train Acc: 45.71%\n",
      "Epoch [3/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [4/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [5/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [6/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [7/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [8/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [9/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [10/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [11/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [12/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [13/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [14/15] Loss: nan Train Acc: 10.00%\n",
      "Epoch [15/15] Loss: nan Train Acc: 10.00%\n",
      "\n",
      "Final Test Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# Device Setup\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ----------------------------\n",
    "# Data (CIFAR-10)\n",
    "# ----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# ResNet Backbone (CIFAR-10)\n",
    "# ----------------------------\n",
    "class ResNet_CIFAR10(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(weights=None)\n",
    "\n",
    "        # Adjust for CIFAR (remove large initial downsampling)\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.backbone.maxpool = nn.Identity()\n",
    "\n",
    "        self.backbone.fc = nn.Linear(\n",
    "            self.backbone.fc.in_features,\n",
    "            embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# ArcFace Layer\n",
    "# ----------------------------\n",
    "class ArcFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, labels):\n",
    "        cosine = F.linear(F.normalize(input),\n",
    "                          F.normalize(self.weight))\n",
    "        cosine = cosine.clamp(-1 + 1e-7, 1 - 1e-7)\n",
    "\n",
    "        theta = torch.acos(cosine)\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n",
    "\n",
    "        output = one_hot * target_logits + (1 - one_hot) * cosine\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model + ArcFace Head\n",
    "# ----------------------------\n",
    "embedding_dim = 128\n",
    "num_classes = 10\n",
    "\n",
    "backbone = ResNet_CIFAR10(embedding_dim).to(device)\n",
    "arcface = ArcFace(embedding_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(backbone.parameters()) +\n",
    "    list(arcface.parameters()),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    backbone.train()\n",
    "    arcface.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            features = backbone(images)\n",
    "            outputs = arcface(features, labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} \"\n",
    "          f\"Train Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Testing\n",
    "# ----------------------------\n",
    "backbone.eval()\n",
    "arcface.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        features = backbone(images)\n",
    "        outputs = arcface(features, labels)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383d350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
